## 大数据常用命令集合



### 1- 文件分发给其它节点   scp 

``` shell
scp -r xxx/xxx node2:xxx/xxx

[root@node1 server]# scp /etc/profile node3:/etc/

```




### 2- Zookeeper
```shell
# zookeeper服务
	zkServer.sh start
	zkServer.sh status
	zkServer.sh stop
# zookeeper client
	zkCli.sh -server nod1:2181
	quit # 退出
```



### 3- 查看java相关的进程jps

``` shell
jps
[root@node1 server]# jps
13952 JobHistoryServer
8321 QuorumPeerMain
14098 Jps
13267 DataNode
13622 NodeManager
13133 NameNode
13518 ResourceManager
[root@node1 server]# 

```





单节点逐个启动 hadoop-daemon.sh

- 在node1主机上使用以下命令启动HDFS NameNode：

``` shell
hadoop-daemon.sh start namenode
```



- 在node2主机上使用以下命令启动HDFS secondarynamenode：

``` shell
[root@node2 current]# hadoop-daemon.sh  start secondarynamenode
```



- 在node1、node2、node3三台主机上，分别使用以下命令启动HDFS DataNode：

``` shell
hadoop-daemon.sh start datanode
```



- 在node1主机上使用以下命令启动YARN ResourceManager：

``` shell
yarn-daemon.sh  start resourcemanager
```



- 在node1、node2、node3三台主机上使用以下命令启动YARN nodemanager：

``` shell
yarn-daemon.sh start nodemanager
```

​	

### 4- 单节点逐个停止

``` shell
只需要把命令中的start改为stop即可。
```



### 5- 脚本一键启动 或 停止 

#### 5-1 启动/停止HDFS

``` shell
start-dfs.sh
stop-dfs.sh
```



#### 5-2 启动/停止Yarn

``` shell
start-yarn.sh
stop-yarn.sh
```



#### 5-2 启动/停止历史任务服务进程

``` shell
mr-jobhistory-daemon.sh start historyserver
mr-jobhistory-daemon.sh stop historyserver

```



### 6- 一键启动、停止HDFS 和 yarn 

**注意** ： 这两个命令可以一键启动HDFS和 YARN , 但是无法启动 启动历史任务服务进程 。

``` shell
Start-all.sh  
stop-all.sh
```



### 7- hadoop命令



Hadoop提供了文件系统的shell命令行客户端，使用方法如下：

``` shell
hadoop  fs  <args>
```



#### 7-1 args:

| **选项名称**   | **使用格式**                                                 | **含义**                   |
| -------------- | ------------------------------------------------------------ | -------------------------- |
| -ls            | -ls <路径>                                                   | 查看指定路径的当前目录结构 |
| -lsr           | -lsr <路径>                                                  | 递归查看指定路径的目录结构 |
| -du            | -du <路径>                                                   | 统计目录下个文件大小       |
| -dus           | -dus <路径>                                                  | 汇总统计目录下文件(夹)大小 |
| -count         | -count [-q] <路径>                                           | 统计文件(夹)数量           |
| -mv            | -mv <源路径> <目的路径>                                      | 移动                       |
| -cp            | -cp <源路径> <目的路径>                                      | 复制                       |
| -rm            | -rm [-skipTrash] <路径>                                      | 删除文件/空白文件夹        |
| -rmr           | -rmr [-skipTrash] <路径>                                     | 递归删除                   |
| -put           | -put <多个linux上的文件> <hdfs路径>                          | 上传文件                   |
| -copyFromLocal | -copyFromLocal <多个linux上的文件> <hdfs路径>                | 从本地复制                 |
| -moveFromLocal | -moveFromLocal <多个linux上的文件> <hdfs路径>                | 从本地移动                 |
| -getmerge      | -getmerge <源路径> <linux路径>                               | 合并到本地                 |
| -cat           | -cat <hdfs路径>                                              | 查看文件内容               |
| -text          | -text <hdfs路径>                                             | 查看文件内容               |
| -copyToLocal   | -copyToLocal [-ignoreCrc] [-crc] [hdfs源路径] [linux目的路径] | 从本地复制                 |
| -moveToLocal   | -moveToLocal [-crc] <hdfs源路径> <linux目的路径>             | 从本地移动                 |
| -mkdir         | -mkdir <hdfs路径>                                            | 创建空白文件夹             |
| -touchz        | -touchz <文件路径>                                           | 创建空白文件               |
| -stat          | -stat [format] <路径>                                        | 显示文件统计信息           |
| -tail          | -tail [-f] <文件>                                            | 查看文件尾部信息           |
| -chmod         | -chmod [-R] <权限模式> [路径]                                | 修改权限                   |
| -chown         | -chown [-R] [属主][:[属组]] 路径                             | 修改属主                   |
| -chgrp         | -chgrp [-R] 属组名称 路径                                    | 修改属组                   |
| -help          | -help [命令选项]                                             | 帮助                       |



#### 7-2 上传文件hadoop fs -put 

将文件上传到HDFS的根目录

``` shell
hadoop fs -put a.txt  /
```

#### 7-2 创建目录 sudo -uhdfs

``` properties
 sudo -uhdfs hadoop  fs -mkdir /spark_config 
```

#### 7-2 修改目录所属用户

``` properties
sudo -uhdfs hadoop fs -chown hadoop:supergroup /spark_config
```





#### 7-3 hadoop checknative

查看当前的hadoop 支持的压缩算法

``` shell
[root@node1 data]# hadoop checknative
21/01/06 16:59:29 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
21/01/06 16:59:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
Native library checking:
hadoop:  true /export/server/hadoop-2.7.5/lib/native/libhadoop.so.1.0.0
zlib:    true /lib64/libz.so.1
snappy:  true /lib64/libsnappy.so.1
lz4:     true revision:99
bzip2:   true /lib64/libbz2.so.1
openssl: false Cannot load libcrypto.so (libcrypto.so: 无法打开共享对象文件: 没有那个文件或目录)!
[root@node1 data]# 

```



#### 7-4 刷新hdfs 

``` shell
hdfs dfsadmin -refreshNodes
```



#### 7-5 刷新yarn

``` shell
yarn rmadmin -refreshNodes
```



#### 7-5 启动一个mapreduce jar任务

``` shell
[root@node1 data]# hadoop jar day09_homework_employe.jar com.fiberhome.mapreduce.JobMain
```







### 8- 安全模式操作命令

``` shell
hdfs  dfsadmin -safemode  get #查看安全模式状态
hdfs  dfsadmin -safemode  enter #进入安全模式
hdfs  dfsadmin -safemode  leave #离开安全模式

hadoop  dfsadmin -safemode  get #查看安全模式状态
hadoop  dfsadmin -safemode  enter #进入安全模式
hadoop  dfsadmin -safemode  leave #离开安全模式
```





### 9- 查看fsimage 信息    hdfs oiv

``` shell
cd /export/server/hadoop-2.7.5/hadoopDatas/namenodeDatas/current
hdfs oiv -i fsimage_0000000000000000138 -p XML -o hello.xml 

oiv : 查看输出文件视图
	o : 输出；
	i : 镜像 fsimage；
	v : view
-p XML ：以什么样的格式解析   XML 

-o  : 输出

```



### 10- 查看edits 信息 hdfs oev

``` shell

cd /export/server/hadoop-2.7.5/hadoopDatas/nn/edits/current
hdfs oev -i  edits_0000000000000000865-0000000000000000866 -p XML -o myedit.xml 

oev : 查看输出文件视图
	o : 输出；
	e : edits；
	v : view
-p XML ：以什么样的格式解析   XML 

-o  : 输出
```





### 11- 集群内部文件拷贝scp

#### 11-1 本地复制到远程

- 方式1：指定用户名，命令执行后需要再输入密码；

``` shell
scp -r local_folder remote_username@remote_ip:remote_folder 
```



 

- 方式2:没有指定用户名，命令执行后需要输入用户名和密码；

``` shell
#注意，如果实现了ssh免密登录之后，则不需要输入密码即可拷贝。
scp -r local_folder remote_ip:remote_folder 
```

- 实例:

``` shell
#复制文件-将 /root/test.txt 拷贝到 192.168.88.161 的 /root/ 目录下，文件名还是 text.txt，使用 root 用户，此时会提示输入远程 root 用户的密码。
scp  /root/test.txt  root@192.168.88.161:/root/

#复制文件并重命名-将 /root/test.txt 拷贝到 192.168.88.161 的 /root/ 目录下，文件名还是 text1.txt，使用 root 用户，此时会提示输入远程 root 用户的密码。
scp  /root/test.txt  root@192.168.88.161:/root/test1.txt

#复制目录-将整个目录 /root/test/ 复制到 192.168.88.161 的 /root/ 下，即递归的复制，使用 root 用户，此时会提示输入远程 root 用户的密码。
scp  -r  /root/test/  root@192.168.88.161:/root/

# 域名
scp -r /root/test  node2:/root/
```

#### 11-2 远程复制到本地

- 远程复制到本地 与 从本地复制到远程命令类似，不同的是 远程文件作为源文件在前，本地文件作为目标文件在后。

 ``` shell
#复制文件-将192.168.88.162的/root目录下的test.txt拷贝到当前主机的/root/目录下，文件名不变
scp root@192.168.88.162:/root/test.txt /root/test.txt


scp node2:/root/test.txt  /root/test.txt
 ```





### 13- 跨集群之间的数据拷贝distcp

- DistCp（distributed copy）是一款被用于大型集群间/集群内的复制工具,该命令的内部原理是MapReduce。

``` shell
cd /export/servers/hadoop-2.7.5/

bin/hadoop distcp hdfs://node1:8020/jdk-8u241-linux-x64.tar.gz  hdfs://cluster2:8020/
```





### 14- hadoop-归档 archive

#### 14-0  hadoop- archive归档的作用

- **解决HDFS小文件过多的问题**；
  - 每个文件会在namenode中创建一个索引；
  - 索引文件过大使得索引速度变慢；
  - 导致MapReduce任务很慢；
- 另外：**Sequence file 、CombineFileInputFormat 、开启JVM重用**等方法都可以解决HDFS小文件过多的问题；
  - **sequeue file** : key为文件名； value为文件内容， 将多个小文件内容合并成一个大文件；
  - **CombineFileInputFormat**:将多个文件合并成一个单独的split 切片；（它会考虑数据的存储位置）
  - **JVM重用**: 一个Map运行一个JVM，在一个MAP在JVM上运行完毕后，这个JVM再继续运行其它的jvm;具体设置（mapreduce.job.jvm.numtasks）

#### 14-1 如何创建Archive

``` shell
[root@node1 data]# hadoop fs -put ./*.txt /config
[root@node1 data]# hadoop archive -archiveName txt.har -p /config/ /outputdir
xxxxxxx

```

#### 14-2 如何查看Archive

``` shell
[root@node1 data]# hadoop fs -ls /outputdir/txt.har
Found 4 items
-rw-r--r--   3 root supergroup          0 2021-01-11 15:13 /outputdir/txt.har/_SUCCESS
-rw-r--r--   5 root supergroup       1577 2021-01-11 15:13 /outputdir/txt.har/_index
-rw-r--r--   5 root supergroup         24 2021-01-11 15:13 /outputdir/txt.har/_masterindex
-rw-r--r--   3 root supergroup  314603998 2021-01-11 15:13 /outputdir/txt.har/part-0

```

#### 14-3 查看归档文件中的小文件,使用har uri

``` shell
hadoop fs -ls har:///outputdir/test.har 

[root@node1 data]# hadoop fs -ls har://hdfs-node1:8020/outputdir/txt.har
Found 8 items
-rw-r--r--   3 root supergroup          6 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/a.txt
-rw-r--r--   3 root supergroup         23 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/aaa.txt
-rw-r--r--   3 root supergroup         23 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/abc.txt
-rw-r--r--   3 root supergroup          6 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/b.txt
-rw-r--r--   3 root supergroup         69 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/big.txt
-rw-r--r--   3 root supergroup          8 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/c.txt
drwxr-xr-x   - root supergroup          0 2021-01-09 17:27 har://hdfs-node1:8020/outputdir/txt.har/mySnapshot1
-rw-r--r--   3 root supergroup  314572800 2021-01-11 15:12 har://hdfs-node1:8020/outputdir/txt.har/testFile.txt
[root@node1 data]# 

```

#### 14-4 查看归档文件中的小文件,不使用har uri

``` shell
hadoop fs -ls har:///outputdir/test.har 
```



#### 14-5 查看某一个小文件内容

``` shell
[root@node1 data]# hadoop fs -cat har:///outputdir/txt.har/a.txt
hello
[root@node1 data]# 

```

#### 14-6 如何解压Archive

``` shell
[root@node1 data]# hadoop fs -mkdir -p /configtxt
[root@node1 data]# hadoop fs -cp har:///outputdir/txt.har/*  /configtxt
[root@node1 data]# 

```

#### 14-7 Archive注意事项

1. Hadoop archives是特殊的档案格式。一个Hadoop archive对应一个文件系统目录。Hadoop archive的扩展名是*.har；
2. 创建archives本质是运行一个Map/Reduce任务，所以应该在Hadoop集群上运行创建档案的命令，要提前启动Yarn集群； 
3. 创建archive文件要消耗和原文件一样多的硬盘空间；
4. .archive文件不支持压缩，尽管archive文件看起来像已经被压缩过；
5. archive文件一旦创建就无法改变，要修改的话，需要创建新的archive文件。事实上，一般不会再对存档后的文件进行修改，因为它们是定期存档的，比如每周或每日；
6. 当创建archive时，源文件不会被更改或删除；



### hdfs-快照



- 开启指定目录的快照

``` shell
root@node1 ~]# hdfs dfsadmin -allowSnapshot /configtxt
Allowing snaphot on /configtxt succeeded
[root@node1 ~]# 

```



- 对指定目录创建快照

``` shell
#注意：创建快照之前，先要允许该目录创建快照
[root@node1 ~]# hdfs dfs -createSnapshot /configtxt
Created snapshot /configtxt/.snapshot/s20210111-162806.667
[root@node1 ~]# 
```

- 通过web浏览器访问快照

``` shell
http://node1:50070/explorer.html#/configtxt/.snapshot/
```

- 指定名称创建快照

``` shell
[root@node1 ~]# hdfs dfs -createSnapshot /configtxt configtxtSnapshot
Created snapshot /configtxt/.snapshot/configtxtSnapshot
[root@node1 ~]# 

```

- ​	重命名快照

``` shell
[root@node1 ~]# 
[root@node1 ~]# hdfs dfs -renameSnapshot /configtxt configtxtSnapshot cofSshot
[root@node1 ~]# hadoop fs -ls /configtxt/.snapshot/
Found 2 items
drwxr-xr-x   - root supergroup          0 2021-01-11 16:30 /configtxt/.snapshot/cofSshot
drwxr-xr-x   - root supergroup          0 2021-01-11 16:28 /configtxt/.snapshot/s20210111-162806.667
[root@node1 ~]# 

```

- 列出当前用户所有可以快照的目录

``` shell
[root@node1 ~]# hdfs lsSnapshottableDir
drwxr-xr-x 0 root supergroup 0 2021-01-11 15:12 2 65536 /config
drwxr-xr-x 0 root supergroup 0 2021-01-11 16:30 2 65536 /configtxt
[root@node1 ~]# 

```

- 恢复快照

``` shell
[root@node1 ~]# hadoop fs -mkdir /configtxt2
[root@node1 ~]# 
[root@node1 ~]# 
[root@node1 ~]# hdfs dfs -cp -ptopax /configtxt/.snapshot/cofSshot/* /configtxt2/
[root@node1 ~]# hadoop fs -ls /configtxt2
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-01-11 16:30 /configtxt2/cofSshot
[root@node1 ~]# 

```

- 删除快照

``` shell
[root@node1 ~]# hdfs dfs -deleteSnapshot /configtxt cofSshot
[root@node1 ~]# 
[root@node1 ~]# hdfs dfs -deleteSnapshot /configtxt s20210111-162806.667
[root@node1 ~]# 

```

- 关闭指定目录的快照

``` shell
[root@node1 ~]# hdfs dfsadmin -disallowsnapshot /configtxt
Disallowing snaphot on /configtxt succeeded
[root@node1 ~]# 


```

